\documentclass[a4paper,titlepage,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=1in]{geometry}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{multirow}
\usepackage[usenames,dvipsnames]{color}
\hypersetup{
	colorlinks,
	pdfauthor=Delan Azabani,
	pdftitle=Programming Languages 200: parser assignment
}
\lstset{basicstyle=\ttfamily, basewidth=0.5em}

\title{Programming Languages 200:\\PL2014 parser assignment}
\date{October 12, 2014}
\author{Delan Azabani}

\pagenumbering{gobble}
\thispdfpagelabel0

\begin{document}

\maketitle

\pagenumbering{arabic}

\section{Overview}

This assignment submission includes a \texttt{Makefile} with the
following rules:

\begin{itemize}
	\item\texttt{PL2014\_check} compiles the main syntax checker,
	\item\texttt{clean} deletes all compiled and generated files,
	\item\texttt{test} executes a suite of 37 unit tests, and
	\item\texttt{report.pdf} typesets this report.
\end{itemize}

The default \texttt{make(1)} rule is \texttt{PL2014\_check}. To see
additional runtime debugging output from the parser that
\texttt{yacc(1)} generates, use \texttt{make YFLAGS=-t} instead.
Included with this submission is a \texttt{.git} directory containing
an uninteresting revision history over the course of my work on this
assignment.

\section{Assumptions and deviations}

I assumed that keywords shall always consist of all capital letters,
thus yielding the convenient property of the keyword and identifier
namespaces failing to overlap.

Furthermore, I assumed that assignment and range delimitation symbols
(\texttt{:=} and \texttt{..} respectively) shall not contain spaces,
indicating the need for unique tokens for them.

In the given syntax graphs, I found it confusing that while
\texttt{declaration\_unit} separated \texttt{DECLARATION} and
\texttt{END} into two tokens, \texttt{END IF}, \texttt{END WHILE},
\texttt{END DO} and \texttt{END FOR} were together in single
rounded rectangles. I chose to standardise on `separate words, separate
tokens' to minimise dependence on any fixed amount of whitespace
between keywords.

Leaving aside the fact that \texttt{statement} can be a
\texttt{compound\_statement}, it appeared inconsistent that
\texttt{if\_statement} would only allow a single \texttt{statement},
while all of the loop constructs allowed multiple statements separated
by semicolons. After checking that it would not introduce any
ambiguity, I upgraded \texttt{if\_statement} in this way.

\newpage

\section{The EBNF grammar}

\texttt{grammar.ebnf} is a conversion of the entire PL2014 grammar from
syntax graphs to the Extended Backus--Naur Form as defined by ISO/IEC
14977:1996(E). Each of the original 33 production rules has an
equivalent with a matching name in the EBNF, in addition to the
following extra rules:

\begin{itemize}
	\item\texttt{constant\_declaration\_fragment} represents any
	     one of the constituent comma-separated equalities in a
	     \texttt{constant\_declaration},
	\item\texttt{variable\_declaration\_fragment} represents any
	     one of the constituent comma-separated declarations in a
	     \texttt{variable\_declaration},
	\item\texttt{compound\_statement\_sequence} represents a
	     semicolon-separated list of at least one statement,
	     excluding \texttt{BEGIN} and \texttt{END},
	\item\texttt{digit} represents any Arabic numeral, and
	\item\texttt{alpha} represents any Latin alphabetic character.
\end{itemize}

The former three rules are present to minimise redundancy and improve
clarity, while the remaining two are necessary because the EBNF
standard doesn't mandate the presence of any character classes, akin
to those one might find in a standard for regular expressions.

\section{The lexical analyser}

\texttt{lexer.l} defines 17 keyword tokens, 17 symbol tokens, two
tokens with variety (\texttt{PL\_NUMBER} and \texttt{PL\_IDENT}), plus
a rule that ignores whitespace, and finally a rule that catches invalid
characters, terminating the analysis of input.

The \texttt{TOKV} function-like preprocessor macro is used to print out
the details of each encountered token with variety. \texttt{TOKE} is
similar, but does not print \texttt{yytext} for fixed symbols.

The order of definition of token rules mattered scarcely because
\texttt{lex(1)} is guaranteed to adhere to the maximal munch principle.
However, the fallback rule which was to catch any invalid character
must come after all other rules matching single characters.

\newpage

\section{The parser}

\texttt{parser.y} defines all 36 internal token identifiers used by
\texttt{lexer.l}. In addition, each of the 34 non-terminal symbols
outlined earlier in the EBNF grammar have been methodically translated
into \texttt{yacc(1)} rules with the same names.

The \texttt{NONT} function-like macro prints a message when a
non-terminal symbol has been completely parsed. Care was taken to
ensure that only left recursion was used in the translation from EBNF
to \texttt{yacc(1)} rules, as that is optimal for a LALR parser
generator.

The following additional rules were required to represent optional
sequences:

\begin{itemize}
	\item\texttt{optional\_const\_and\_constant\_declaration},
	\item\texttt{optional\_var\_and\_variable\_declaration},
	\item\texttt{optional\_type\_declaration},
	\item\texttt{optional\_procedure\_interface},
	\item\texttt{optional\_function\_interface}, and
	\item\texttt{optional\_formal\_parameters}.
\end{itemize}

Optional sequences took the form:

\begin{lstlisting}
optional_thing :
               { NONT(optional_thing) }
               | thing
               { NONT(optional_thing) }
\end{lstlisting}

The following additional rules were required to represent repeating,
symbol-delimited sequences of at least one element:

\begin{itemize}
	\item\texttt{comma\_constant\_declaration\_fragments},
	\item\texttt{comma\_variable\_declaration\_fragments},
	\item\texttt{comma\_idents},
	\item\texttt{semicolon\_idents},
	\item\texttt{semicolon\_statements},
	\item\texttt{add\_subtract\_terms}, and
	\item\texttt{multiply\_divide\_id\_nums}.
\end{itemize}

Repeated sequences took the form:

\begin{lstlisting}
delimiter_things : thing
                 { NONT(optional_thing) }
                 | delimiter_things
                   delimiter
                   thing
                 { NONT(optional_thing) }
\end{lstlisting}

\end{document}
